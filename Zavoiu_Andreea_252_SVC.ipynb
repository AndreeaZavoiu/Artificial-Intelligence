{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb270b11-2099-4244-8b63-968e99fd03b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdb90af0-8c10-4fd6-8fb1-c11a192626ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preluat din lab4\n",
    "class Bag_of_words:\n",
    "    def __init__(self):\n",
    "        self.vocabulary = {}\n",
    "        self.vocabulary_length = 0\n",
    "\n",
    "    def build_vocabulary(self, data):\n",
    "        for document in data: # text din lista de texte\n",
    "            for word in document:\n",
    "                if word not in self.vocabulary.keys():  # creeaza un dictionar in care cheile sunt cuvintele \n",
    "                    self.vocabulary[word] = len(self.vocabulary)\n",
    "        self.vocabulary_length = len(self.vocabulary)\n",
    "        \n",
    "    # returneaza vectorul in care cuvintelor le-a fost asignat un index, iar ca valoare s-a pus frecventa acestora in seturile de antrenare, validare si testare, pe baza vocabularului din setul de antrenare    \n",
    "    def get_features(self, data):\n",
    "        features = np.zeros((len(data), self.vocabulary_length))\n",
    "        for document_idx, document in enumerate(data): # id-ul textului este pus ca indice de linie in vectorul de feature-uri => cate texte atatea linii\n",
    "            for word in document:                      # coloanele reprezinta fiecare cuvant din vocabularul de pe setul de antrenare\n",
    "                if word in self.vocabulary.keys():\n",
    "                    features[document_idx, self.vocabulary[word]] += 1 # valoarea de la acest cuvant din acest text este frecventa de aparitie\n",
    "        return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "413a0af3-4d8e-4d05-81fb-dff69a66a96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preluat din lab4\n",
    "def accuracy_score(true_labels, predicted_labels):\n",
    "    return (true_labels==predicted_labels).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5208464-e4dc-4970-9edc-e6b89db66cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# preluat din lab4\n",
    "def normalize_data(train_data, test_data, type=None):\n",
    "    scaler = None\n",
    "    if type == 'l1':\n",
    "        scaler = preprocessing.Normalizer(norm='l1')\n",
    "\n",
    "    elif type == 'l2':\n",
    "        scaler = preprocessing.Normalizer(norm='l2')\n",
    "\n",
    "    if scaler is not None:\n",
    "        scaler.fit(train_data)\n",
    "        scaled_train_data = scaler.transform(train_data)\n",
    "        scaled_test_data = scaler.transform(test_data) \n",
    "        return (scaled_train_data, scaled_test_data)\n",
    "    else:\n",
    "        print(\"No scaling was performed. Raw data is returned.\")\n",
    "        return (train_data, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b080eee-400f-4534-a665-c0737f3988b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample_stuff = pd.read_csv('data/train_samples.txt', sep='\t', header=None)\n",
    "# retin doar textele intr-un array (fara id-ul de la inceput)\n",
    "train_samples = train_sample_stuff[1]\n",
    "\n",
    "train_label_stuff = pd.read_csv('data/train_labels.txt', sep = '\\t', header=None)\n",
    "# retin doar label-urile intr-un array (fara id-ul de la inceput)\n",
    "train_labels = train_label_stuff[1]\n",
    "\n",
    "# retin o lista de cuvinte pentru intregul set de date de antrenare, pe care o voi folosi in Bag_of_words pentru a obtine frecventa fiecaruia in set\n",
    "train_list = [word.split() for word in train_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f049caec-d5ea-4cc2-bbe9-ab475b152d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_sample_stuff = pd.read_csv('data/validation_samples.txt', sep='\t', header=None)\n",
    "validation_samples = validation_sample_stuff[1]\n",
    "validation_label_stuff = pd.read_csv('data/validation_labels.txt', sep='\t', header=None)\n",
    "validation_labels = validation_label_stuff[1]\n",
    "validation_list = [word.split() for word in validation_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fad6e2d-b097-41bd-ae40-a453f71cc515",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample_stuff = pd.read_csv('data/test_samples.txt', sep='\t', header=None)\n",
    "test_samples = test_sample_stuff[1]\n",
    "test_list = [word.split() for word in test_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc930c75-399f-4656-9674-ac1aa832895c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construieste vocabularul pe baza frecventei de aparitie a cuvintelor in textele din setul de antrenare\n",
    "bow_model = Bag_of_words()\n",
    "bow_model.build_vocabulary(train_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "68ecd7ce-77d0-4a86-902d-81e25691e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# salvez vectorul de frecvente pentru fiecare cuvant\n",
    "train_features = bow_model.get_features(train_list)\n",
    "validation_features = bow_model.get_features(validation_list)\n",
    "test_features = bow_model.get_features(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d6e854b1-8f8d-4610-88b0-799b311b4594",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pentru unele teste (ineficiente) am folosit normalizarea\n",
    "# scaled_train_data, scaled_validation_data = normalize_data(train_features, validation_features, type='l2')\n",
    "scaled_train_data = train_features\n",
    "scaled_validation_data = validation_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1e4e3-230e-42ef-b928-93b2ba1ded24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# definesc modelul Support-Vector Classification din biblioteca Masinilor de Vectori Suport\n",
    "svm_model = svm.SVC(C=12, kernel='rbf')\n",
    "\n",
    "# antrenez modelul pe setul de training\n",
    "svm_model.fit(scaled_train_data, train_labels)\n",
    "\n",
    "# prezic label-urile pe setul de validare pentru a vedea performanta modelului, intrucat stiu deja label-urile corecte\n",
    "predicted_labels_svm = svm_model.predict(scaled_validation_data)\n",
    "model_accuracy_svm = accuracy_score(np.asarray(validation_labels), predicted_labels_svm)\n",
    "print(\" => accuracy: \", model_accuracy_svm * 100)\n",
    "\n",
    "# prezic label-urile si pe setul de testare\n",
    "predicted_test_labels_svm = svm_model.predict(test_features) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc60598-d0f3-4fb1-aaa0-bb1e3f208239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRIEREA LABEL-URILOR IN FISIERUL TEXT DE SUBMISIE\n",
    "\n",
    "# x este lista pe care o voi scrie in fisierul de submisie\n",
    "x = [['id','label']]\n",
    "test_ids = test_sample_stuff[0]\n",
    "\n",
    "for i in range(len(test_sample_stuff)):\n",
    "    row = []\n",
    "    predicted_label = predicted_test_labels_svm[i]\n",
    "    row.append(test_ids[i])\n",
    "    row.append(predicted_label)\n",
    "    x.append(row)\n",
    "\n",
    "np.savetxt('submisii/sample_submission.txt', x, delimiter=',', newline='\\n', fmt='%s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
